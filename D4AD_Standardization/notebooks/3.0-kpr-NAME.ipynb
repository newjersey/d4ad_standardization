{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries \n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "done\n"
    }
   ],
   "source": [
    "# Function to pad CIP codes to 6 digits\n",
    "def pad_cipcodes(cip_series):\n",
    "    \"\"\"\n",
    "    Ensure CIP codes are 6 digits by prepending a zero if necessary.\n",
    "    \"\"\"\n",
    "    return cip_series.astype(str).str.zfill(6)\n",
    "\n",
    "rootpath = \"/hdd/work/d4ad_standardization/\"\n",
    "filepath = \"./D4AD_Standardization/data/raw/etpl_all_programsJune3.xls\"\n",
    "\n",
    "columns = [\n",
    "    \"NAME\",\n",
    "    \"NAME_1\",\n",
    "    \"DESCRIPTION\",\n",
    "    \"PREREQUISITES\",\n",
    "    \"FEATURESDESCRIPTION\",\n",
    "    \"STREET1\",\n",
    "    \"CITY\",\n",
    "    \"STATE\",\n",
    "    \"ZIP\",\n",
    "    \"WEBSITE\",\n",
    "    \"COUNTY\",\n",
    "    \"NONGOVAPPROVAL\",\n",
    "    \"STATECOMMENTS\",\n",
    "    \"CIPCODE\",\n",
    "    \"PROVIDERID\",\n",
    "    \"APPROVINGAGENCYID\"\n",
    "]\n",
    "\n",
    "df = pd.read_excel(rootpath + filepath, usecols=columns)\n",
    "print('done')\n",
    "\n",
    "# Apply the padding function to the CIPCODE column\n",
    "df['CIPCODE'] = pad_cipcodes(df['CIPCODE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "done\n"
    }
   ],
   "source": [
    "# Set up columns to keep, fields, locations for writing\n",
    "processedpath = \"./D4AD_Standardization/data/processed/\"\n",
    "interimpath = \"./D4AD_Standardization/data/interim/\"\n",
    "\n",
    "content_is = \"standardized_name.csv\"\n",
    "\n",
    "the_df = df # df.sample(n=100, random_state=42)\n",
    "\n",
    "columns_to_save = ['STANDARDIZEDNAME'] + columns #['STANDARDIZEDNAME', 'NAME', 'PROVIDERID',\n",
    "                    #'APPROVINGAGENCYID', 'CIPCODE']\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's transform this column into a final version...\n",
    "\n",
    "# 1) we cover the simplest case of hyphenation\n",
    "the_df['STANDARDIZEDNAME'] = the_df.NAME.str.split(\" - \", n=1).str[0] # content before -\n",
    "\n",
    "# 2) then cover cases of 'X-'\n",
    "regex_pattern = '''\n",
    "                ^                   # start from beginning\n",
    "                (.+?                # capture everything non-greedily ...\n",
    "                    (?:(?!-\\s)      # ... except for the '- ', if it's there\n",
    "                        .)          # and continue to match any character\n",
    "                *)                  # ... as many times as we can\n",
    "                '''\n",
    "\n",
    "the_df.STANDARDIZEDNAME =\\\n",
    "    the_df.STANDARDIZEDNAME.str.extract(regex_pattern, flags=re.VERBOSE)\n",
    "\n",
    "# 3) Then go after odd static patterns that are commeon\n",
    "# ... people like to put the color orange, closed in the name of the provider\n",
    "the_df.STANDARDIZEDNAME =\\\n",
    "    the_df.STANDARDIZEDNAME.str.replace(\"\\(orange\\)\",\"\", case=False)\n",
    "the_df.STANDARDIZEDNAME =\\\n",
    "    the_df.STANDARDIZEDNAME.str.replace(\"closed\",\"\", case=False)\n",
    "\n",
    "# # todo: check the data, maybe 200 cases to get the Jeffrey's interval here\n",
    "# pd.set_option('display.max_rows', None)\n",
    "# the_df.sample(n=100)[['STANDARDIZEDNAME', 'NAME']] # see some rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... finally we can write this out as our first complete lookup table\n",
    "# for the NAME field\n",
    "the_df.to_csv(rootpath + interimpath + \"{}\".format(content_is),\n",
    "              index = False,\n",
    "              chunksize = 10000,\n",
    "              columns=columns_to_save)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37264bitd4adstandardizationpipenvcac7d9f4a0864f29b6353caf0213501a",
   "display_name": "Python 3.7.2 64-bit ('d4ad_standardization': pipenv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
