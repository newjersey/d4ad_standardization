{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "done\n"
    }
   ],
   "source": [
    "# Importing the libraries \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "import re\n",
    "import os\n",
    "import zipfile\n",
    "from statsmodels.stats.proportion import proportion_confint\n",
    "# active labeler related\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import ComplementNB  # corrects for class imbalance, SGD is pretty good too\n",
    "from sklearn.pipeline import Pipeline\n",
    "from superintendent import ClassLabeller\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(analyzer='char', ngram_range=(1,2))),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', ComplementNB()),\n",
    "])\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "done\n"
    }
   ],
   "source": [
    "# Set up columns to keep, fields, locations for writing\n",
    "rootpath = \"/hdd/work/d4ad_standardization/\"\n",
    "processedpath = \"D4AD_Standardization/data/processed/\"\n",
    "externalpath = \"D4AD_Standardization/data/external/\"\n",
    "interimpath = \"D4AD_Standardization/data/interim/\"\n",
    "\n",
    "content_is = \"standardized_name_and_name1\"\n",
    "\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "done\n"
    }
   ],
   "source": [
    "\n",
    "filepath = \"./D4AD_Standardization/data/raw/etpl_all_programsJune3.xls\"\n",
    "filepath = \"standardized_name.csv\" # builds off of notebook 3 work\n",
    "\n",
    "columns = [\n",
    "    \"NAME_1\",\n",
    "    \"STANDARDIZEDNAME\",\n",
    "    \"NAME\",\n",
    "    \"DESCRIPTION\",\n",
    "    \"PREREQUISITES\",\n",
    "    \"FEATURESDESCRIPTION\",\n",
    "    \"STREET1\",\n",
    "    \"CITY\",\n",
    "    \"STATE\",\n",
    "    \"ZIP\",\n",
    "    \"WEBSITE\",\n",
    "    \"COUNTY\",\n",
    "    \"NONGOVAPPROVAL\",\n",
    "    \"STATECOMMENTS\",\n",
    "    \"CIPCODE\",\n",
    "    \"PROVIDERID\",\n",
    "    \"APPROVINGAGENCYID\"\n",
    "]\n",
    "\n",
    "columns_to_save = ['STANDARDIZEDNAME_1'] + columns\n",
    "\n",
    "SKIP_THIS = True # helps me be able to run all and not worry about pulling things\n",
    "# I already know I have on disk\n",
    "\n",
    "#df = pd.read_excel(rootpath + interimpath + filepath, usecols=columns)\n",
    "df = pd.read_csv(rootpath + interimpath + filepath, usecols=columns)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "done\n"
    }
   ],
   "source": [
    "if not SKIP_THIS:\n",
    "    ONET_TOOLS_TECH_URL_NAME = (\"https://www.onetcenter.org/dl_files/database/db_20_1_text/Tools%20and%20Technology.txt\", \"onet_tools_tech.csv\")\n",
    "    CAREERONESTOP_CERTIFICATIONS_URL_NAME = (\"https://www.careeronestop.org/TridionMultimedia/tcm24-48614_CareerOnestop_Certifications_07072020.zip\", \"career_one_stop.zip\")\n",
    "\n",
    "    filepath = rootpath + externalpath\n",
    "\n",
    "    for dataset in (ONET_TOOLS_TECH_URL_NAME, CAREERONESTOP_CERTIFICATIONS_URL_NAME):\n",
    "        url, filename = dataset\n",
    "        print(\"running ...\", f'\\nwget -O {filepath+filename} {url}')\n",
    "        os.system(f'wget -O {filepath+filename} {url}')\n",
    "        print(\"filetype is\",  filename[-3:])\n",
    "\n",
    "        if filename[-3:] == 'zip':\n",
    "            with zipfile.ZipFile(filepath+filename,\"r\") as zip_ref:\n",
    "                zipdir = filepath+filename[:-4]\n",
    "                print(\"unzipping {} to ...\".format(filename), zipdir)\n",
    "                os.mkdir(zipdir)\n",
    "                zip_ref.extractall(zipdir)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', False)\n",
    "\n",
    "the_df = df #df.sample(n=10000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "done\n"
    }
   ],
   "source": [
    "# A) \n",
    "# The program or course name can start or end with a matching parenthesis. In these cases\n",
    "# we assume that no other matching parenthesis are present and apply \n",
    "# an appropriate regex for that...\n",
    "\n",
    "# First, set up standardized column with default values\n",
    "the_df[\"STANDARDIZEDNAME_1\"] = \"\"\n",
    "\n",
    "# ... then extract names for those with opening parens\n",
    "open_parenthesis_index = the_df.NAME_1.str[0] == '('\n",
    "open_parenthesis_regex = '''\n",
    "                (?P<paren>\\(.*\\)) # get the first parathesis\n",
    "                (?P<the_name>.*)  # then get the actual name\n",
    "                '''\n",
    "\n",
    "the_df.loc[open_parenthesis_index, \"STANDARDIZEDNAME_1\"] =\\\n",
    "    the_df.loc[open_parenthesis_index, 'NAME_1']\\\n",
    "          .str\\\n",
    "          .extract(open_parenthesis_regex, flags=re.VERBOSE).the_name\n",
    "\n",
    "# ... then extract names for those with closing parens\n",
    "close_parenthesis_index = the_df.NAME_1.str[-1] == ')'\n",
    "closing_parenthesis_regex = '''\n",
    "                (?P<the_name>.*)  # get the actual name\n",
    "                (?P<paren>\\(.*\\)) # get the last parathensis                \n",
    "                '''\n",
    "the_df.loc[close_parenthesis_index, \"STANDARDIZEDNAME_1\"] =\\\n",
    "    the_df.loc[close_parenthesis_index, 'NAME_1']\\\n",
    "          .str\\\n",
    "          .extract(closing_parenthesis_regex, flags=re.VERBOSE).the_name\n",
    "\n",
    "# ... then we copy over content that has a internal parenthesis with those\n",
    "# parenthesis removed and ignore everything after, e.g. \"ABC (123) DEF\" --> \"ABC\"\n",
    "internal_parenthesis_index =\\\n",
    "    the_df['NAME_1'].str.contains('\\(|\\)', regex=True) &\\\n",
    "        ~(close_parenthesis_index|open_parenthesis_index)\n",
    "\n",
    "the_df.loc[internal_parenthesis_index, \"STANDARDIZEDNAME_1\"] =\\\n",
    "    the_df.loc[internal_parenthesis_index, 'NAME_1']\\\n",
    "          .str\\\n",
    "          .extract(closing_parenthesis_regex, flags=re.VERBOSE).the_name\n",
    "\n",
    "# ... finally, just copy over everything else\n",
    "no_parenthesis_index = ~(close_parenthesis_index |\\\n",
    "                         open_parenthesis_index  |\\\n",
    "                         internal_parenthesis_index)\n",
    "the_df.loc[no_parenthesis_index, \"STANDARDIZEDNAME_1\"] =\\\n",
    "    the_df.loc[no_parenthesis_index, 'NAME_1']\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "constructed abbreviation list...\ndone\n"
    }
   ],
   "source": [
    "# 2)\n",
    "# So now we have silver version data of program, course names\n",
    "# from the cell above, in STANDARDIZEDNAME_1\n",
    "#\n",
    "# To make an incrementally better version we need to expand \n",
    "# abbreviations and acroynmns.\n",
    "\n",
    "# **We do this if we don't skip things and the labeling file does not exist**\n",
    "\n",
    "# Here I identify two pretty common cases of acronymns and abbreviations:\n",
    "#   All caps\n",
    "#   Xx*. <- capitalized inital letter ending with a period\n",
    "\n",
    "# Now let's attempt to extract presumed acronyms and see if we can\n",
    "# directly label them. I assume there are far fewer unique abbreviations\n",
    "# so that a person can actually do this in a short amount of time\n",
    "abbreviation_pickle = rootpath + interimpath + 'abbreviation_label.pickle'\n",
    "\n",
    "if os.path.exists(abbreviation_pickle):\n",
    "    flags = re.VERBOSE\n",
    "\n",
    "    #  TODO: check if abbreviation labeled file already exists, if it does\n",
    "    # we skip this portion\n",
    "\n",
    "    # Pandas/Python doesn't like this verbose regex but likes other?\n",
    "    # all_caps_regex = '''\n",
    "    #                 \\b(?P<all_caps>[A-Z]+)  # Get all caps words\n",
    "    #                 [\\s,:\\d]                # sit before a space, comma or digit\n",
    "    #                 '''\n",
    "    all_caps_regex = r'\\b(?P<all_caps>[A-Z]+)[\\s,:\\d]'\n",
    "\n",
    "    dotted_word_regex = r'(?P<dot_abbreviation>[A-Z][a-z]+\\.)'\n",
    "    dotted_word_regex =\\\n",
    "        \"\"\"\n",
    "        (?P<dot_abbreviation>[a-zA-Z][a-z]+\\.)\n",
    "        \"\"\"\n",
    "\n",
    "    the_regexs = \"|\".join([all_caps_regex, dotted_word_regex])\n",
    "\n",
    "    the_abbreviations =\\\n",
    "        the_df['STANDARDIZEDNAME_1'].str\\\n",
    "                                    .extractall(\n",
    "                                        pat=the_regexs,\n",
    "                                        flags=flags)\n",
    "    print('constructed abbreviation list...')\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "created interim abbreviations data frame...\ndone\n"
    }
   ],
   "source": [
    "# Since we've run on the entire dataset we can now\n",
    "# flatten the dataframe, de-duplicate and then directly label\n",
    "if os.path.exists(abbreviation_pickle):\n",
    "    len(the_abbreviations.all_caps.unique()) +\\\n",
    "        len(the_abbreviations.dot_abbreviation.unique()) # 1151\n",
    "\n",
    "    # now we need to get the count of unique abbreviations so that we can\n",
    "    # label in priority order. We also drop those abbreviations only occuring once\n",
    "    # since they have a 1 / 26,660 chance of occuring (not worth our effort)\n",
    "\n",
    "    # to properly label the all caps and abbreviations we need the \n",
    "    # context in which they occur. Since we're mapping to one definition\n",
    "    # we assume only the first instance is really needed and label off of that\n",
    "    abbreviations_to_label =\\\n",
    "        pd.concat(\n",
    "            (the_abbreviations.drop_duplicates(\n",
    "                subset=['all_caps'],\n",
    "                keep='first')['all_caps'],\n",
    "            the_abbreviations.drop_duplicates(\n",
    "                subset=['dot_abbreviation'],\n",
    "                keep='first')['dot_abbreviation']\n",
    "            ),\n",
    "            axis=0\n",
    "        ).dropna()\\\n",
    "        .droplevel('match')\\\n",
    "        .reset_index() # so that index is a column\n",
    "\n",
    "    abbreviations_to_label.rename(columns={'index':'the_df_index', 0:'abbreviation'}, inplace=True)\n",
    "    print('created interim abbreviations data frame...')\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "created mapping columns for former labels and their expansions...\n"
    }
   ],
   "source": [
    "if os.path.exists(abbreviation_pickle):\n",
    "    # note here we read the main pickle file and assume \n",
    "    # those pickle files with random extensiosn were/are consolidated into this\n",
    "    # the other pickle files are named to prevent overwriting ongoing work\n",
    "    expanded_labels = pd.read_pickle(abbreviation_pickle)\n",
    "    last_labeled_index = expanded_labels.index(None)\n",
    "    former_labels = abbreviations_to_label.abbreviation[:last_labeled_index] #set(already_labeled[:last_labeled_index])\n",
    "\n",
    "    unseen_abbreviations =\\\n",
    "        abbreviations_to_label.query('abbreviation not in @former_labels')\n",
    "    unseen_abbreviations.abbreviation.value_counts()\n",
    "    # note I'm seeing 1 across the board, both when using not in and in\n",
    "    #   which suggests that we leave these be for now because their occurence\n",
    "    # is so rare out of 26,660, although the bulk may be significant; better\n",
    "    # to circle back though\n",
    "    print('created mapping columns for former labels and their expansions...')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "done/skipped manual labelling\n"
    }
   ],
   "source": [
    "#  So now we manually label them and dump them here\n",
    "#  This is the procedure we follow\n",
    "#       A) if a capitalized word is an entire word, leave it alone (no label)\n",
    "#       B) provide a label for all dotted abbreviated words\n",
    "if not SKIP_THIS:\n",
    "    def display_func(row):\n",
    "        # Note: We use globally available the_df to get context, bad form I know\n",
    "        display(\n",
    "            Markdown(\n",
    "                \"**Context:** \" +  the_df.loc[ row.the_df_index ].NAME_1 \\\n",
    "            +   \"\\n\\n\" + row.abbreviation\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def preprocessor(x, y):\n",
    "        # only take standardized column, leave everything else\n",
    "        return x.abbreviation, y\n",
    "\n",
    "    if os.path.exists(abbreviation_pickle) and not SKIP_THIS:\n",
    "        labelling_widget = ClassLabeller(\n",
    "            features=abbreviations_to_label,\n",
    "            model=pipeline,\n",
    "            model_preprocess=preprocessor,\n",
    "            display_func=display_func,\n",
    "            options=['No Label'],\n",
    "            acquisition_function='entropy'\n",
    "        )\n",
    "\n",
    "        labelling_widget\n",
    "print('done/skipped manual labelling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#  Every now and then, with the labels in hand we simply output them (if a file doesn't already exist)\n",
    "# so that we can save them incrementally. We should manually rename older files; this should\n",
    "# be basically a 1 time process.\n",
    "\n",
    "# Temp, save work locally so we don't loooooose it! \n",
    "if os.path.exists(abbreviation_pickle) and not SKIP_THIS:\n",
    "    import random\n",
    "    random_number = str(random.randint(0,255))\n",
    "    pickle.dump(expanded_labels,\n",
    "                open(abbreviation_pickle+random_number, 'wb'))\n",
    "    print(\"done/don't forget to consolidate abbreviations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                     MULTI_REPLACE_STANDARDIZEDNAME_1  \\\n0                  Automated Office Systems Processor   \n1   Business Software App/Office Proc.Legal/Mach.T...   \n2     Business Software App./Comp.Office Proc.Medical   \n3                      Microsoft Office Specialist II   \n4                   Computerized Financial Accounting   \n5                           Introduction to Computers   \n6   Heating, Ventilation and Air Conditioning Prin...   \n7                                         Cosmetology   \n8              Diesel Mechanics Technology/Technician   \n9         Electrical - Technical & Apprentice-4 Years   \n10                                    Microsoft Excel   \n11                    Industrial Maintenance Mechanic   \n12                              Machine Shop Practice   \n13                               Manicuring Licensing   \n14                          TCP/IP and Cisco Networks   \n15              Mini Master of Business Adminstration   \n16                  TCP/IP and Cisco Networks Diploma   \n17   LAN, Wide Area Network and Communication Diploma   \n18  Microsoft Certified Solutions Expert Windows 2...   \n19                                    Oracle and Unix   \n20                                    Oracle and Unix   \n21   Oracle Oracle Certification Program and C++/Java   \n22  A+/N+/Microsoft Certified Solutions Expert Win...   \n23  Microsoft Certified Solutions Expert Windows 2000   \n24  N+/Cisco Certified Networking Associate/Micros...   \n25  Unix/Cisco Certified Networking Associate/Cisc...   \n26     Associate of Applied Science - Web Development   \n27              Web Dev., XML and Java Script Diploma   \n28                 Construction Trades Pre-Apprentice   \n29        Continuing Education Basic Selling Workshop   \n30               Microsoft Power Point 2007 - Evening   \n31                     Certified Nurse Aide - Evening   \n32                                       A+ - Evening   \n33                    Certified Phlebotomy Technician   \n34                           Basic Plumbing - Evening   \n35                           Digital Camera - Evening   \n36  High School Equivalency Exam Preparation (HSE)...   \n37                     Criminal Justice - Certificate   \n38  Liberal Arts/Education - Associate in Arts Degree   \n39   Liberal Arts/Women's Studies - Associate in Arts   \n40                         Licensed Practical Nursing   \n41              TCP/IP and Cisco Networks Certificate   \n42                                 Project S.H.A.R.E.   \n43           Microsoft Certified System Administrator   \n44                Microsoft Certified System Engineer   \n45                                 Farm Stand Project   \n46                        Literacy Skills Development   \n47                  Career Exploration & Study Skills   \n48  Straight Truck Driver - Commerical Driver's Li...   \n49  School Bus Driver - Commerical Driver's Licens...   \n50             Computerized Medical Office Specialist   \n51          Commerical Driver's License Class Class A   \n52   Commerical Driver's License Class Class A w/ \"P\"   \n53             A+/N+/Microsoft Office User Specialist   \n54                   Microsoft Office User Specialist   \n55                                         A+/N+/Unix   \n56  Microsoft Certified Solutions Expert Win2K/Cis...   \n57              Automotive Engine Performance(AEP.CT)   \n58            Black Seal Advanced/Stationary Engineer   \n59                Medical Billing & Coding Specialist   \n60                                 Medical Assistant    \n61                      Microsoft Office Applications   \n62               Computer Network & Technical Support   \n63                Microsoft Certified System Engineer   \n64                        Computerized Medical Office   \n65       Personal Computer Assembly & Troubleshooting   \n66                 Office Assistant Specialist Series   \n67                               Image Graphic Design   \n68            Oracle Developer/2000 & Web Application   \n69                                 Network Specialist   \n70                        Adobe Photoshop CS Advanced   \n71                                Finance Certificate   \n72                            Accountancy Certificate   \n73                    Business Management Certificate   \n74                   International Business and Trade   \n75                     Management Information Systems   \n76                            High School Equivalence   \n77                                  Microsoft Project   \n78                                    Microsoft Visio   \n79                      Adult Basic Education Program   \n80                 Office Support Assistant (Day/Eve)   \n81             Computer-aided design I & II - 2 years   \n82                Automotive Technology - Certificate   \n83                     Automotive Mechanics - General   \n84  Basics - Blue Print Reading I - Machine/Buildi...   \n85                           Administrative Assistant   \n86           Statistical Analysis (SAS, Clinical SAS)   \n87                     Oracle Database Administration   \n88                                  Paralegal Studies   \n89                              Fashion Merchandising   \n90      General Education Diploma & Computer Literacy   \n91                                   Legal  Assistant   \n92            Medical Assisting                         \n93  Business Administration with Computerized Acco...   \n94  Shielded Metal Arc Welding Shielded Metal Arc ...   \n95  Gas Tungsten Arc Welding 3/4G/American Welding...   \n96                                Executive Assistant   \n97                        Welding Technology/ Welder    \n98                                     Microsoft Word   \n99  Oracle Certified Professional Database Adminis...   \n\n                                               NAME_1  \n0                  Automated Office Systems Processor  \n1   Bus.Soft. App/Office Proc.Legal/Mach.Transcrip...  \n2             Bus.Soft. App./Comp.Office Proc.Medical  \n3                      Microsoft Office Specialist II  \n4                   Computerized Financial Accounting  \n5                           Introduction to Computers  \n6   HVAC Principals I, III, Math - Certificate w/MCCC  \n7                                         Cosmetology  \n8              Diesel Mechanics Technology/Technician  \n9         Electrical - Technical & Apprentice-4 Years  \n10                                           MS Excel  \n11                    Industrial Maintenance Mechanic  \n12                              Machine Shop Practice  \n13                               Manicuring Licensing  \n14                          TCP/IP and Cisco Networks  \n15                                           Mini MBA  \n16                  TCP/IP and Cisco Networks Diploma  \n17                 LAN, WAN and Communication Diploma  \n18                                   MCSE Win 2K/Unix  \n19                                    Oracle and Unix  \n20                                    Oracle and Unix  \n21                            Oracle OCP and C++/Java  \n22                                  A+/N+/MCSE win 2K  \n23                                  MCSE Windows 2000  \n24                                N+/CCNA/MCSE win 2K  \n25                                     Unix/CCNA/CCNP  \n26                              AAS - Web Development  \n27              Web Dev., XML and Java Script Diploma  \n28                 Construction Trades Pre-Apprentice  \n29                  Contg. Ed. Basic Selling Workshop  \n30               Microsoft Power Point 2007 - Evening  \n31                     Certified Nurse Aide - Evening  \n32                                       A+ - Evening  \n33                    Certified Phlebotomy Technician  \n34                           Basic Plumbing - Evening  \n35                           Digital Camera - Evening  \n36  High School Equivalency Exam Preparation (HSE)...  \n37                     Criminal Justice - Certificate  \n38                 Liberal Arts/Education - AA Degree  \n39                  Liberal Arts/Women's Studies - AA  \n40                         Licensed Practical Nursing  \n41              TCP/IP and Cisco Networks Certificate  \n42                                 Project S.H.A.R.E.  \n43           Microsoft Certified System Administrator  \n44                Microsoft Certified System Engineer  \n45                                 Farm Stand Project  \n46                        Literacy Skills Development  \n47                  Career Exploration & Study Skills  \n48                      Straight Truck Driver - CDL B  \n49              School Bus Driver - CDL B w/ P\" & \"S\"  \n50             Computerized Medical Office Specialist  \n51                                              CDL A  \n52                                       CDL A w/ \"P\"  \n53                                         A+/N+/Mous  \n54                                               MOUS  \n55                                         A+/N+/Unix  \n56                               MCSE Win2K/CCNA/CCNP  \n57              Automotive Engine Performance(AEP.CT)  \n58            Black Seal Advanced/Stationary Engineer  \n59                Medical Billing & Coding Specialist  \n60                                 Medical Assistant   \n61                      Microsoft Office Applications  \n62               Computer Network & Technical Support  \n63                       MS Certified System Engineer  \n64                        Computerized Medical Office  \n65                      PC Assembly & Troubleshooting  \n66                 Office Assistant Specialist Series  \n67                               Image Graphic Design  \n68            Oracle Developer/2000 & Web Application  \n69                                 Network Specialist  \n70                        Adobe Photoshop CS Advanced  \n71                                Finance Certificate  \n72                            Accountancy Certificate  \n73                    Business Management Certificate  \n74                   International Business and Trade  \n75                     Management Information Systems  \n76                            High School Equivalence  \n77                                  Microsoft Project  \n78                                    Microsoft Visio  \n79                      Adult Basic Education Program  \n80                 Office Support Assistant (Day/Eve)  \n81                               CAD I & II - 2 years  \n82                Automotive Technology - Certificate  \n83                     Automotive Mechanics - General  \n84  Basics - Blue Print Reading I - Machine/Buildi...  \n85                           Administrative Assistant  \n86           Statistical Analysis (SAS, Clinical SAS)  \n87                     Oracle Database Administration  \n88                                  Paralegal Studies  \n89                              Fashion Merchandising  \n90                            GED & Computer Literacy  \n91                                   Legal  Assistant  \n92            Medical Assisting                        \n93  Business Administration with Computerized Acco...  \n94                 SMAW Shielded Metal Arc Welding-4G  \n95      Gas Tungsten Arc Welding 3/4G/AWS Prep Course  \n96                                Executive Assistant  \n97                        Welding Technology/ Welder   \n98                                            MS Word  \n99                  Oracle Certified Professional DBA  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MULTI_REPLACE_STANDARDIZEDNAME_1</th>\n      <th>NAME_1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Automated Office Systems Processor</td>\n      <td>Automated Office Systems Processor</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Business Software App/Office Proc.Legal/Mach.T...</td>\n      <td>Bus.Soft. App/Office Proc.Legal/Mach.Transcrip...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Business Software App./Comp.Office Proc.Medical</td>\n      <td>Bus.Soft. App./Comp.Office Proc.Medical</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Microsoft Office Specialist II</td>\n      <td>Microsoft Office Specialist II</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Computerized Financial Accounting</td>\n      <td>Computerized Financial Accounting</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Introduction to Computers</td>\n      <td>Introduction to Computers</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Heating, Ventilation and Air Conditioning Prin...</td>\n      <td>HVAC Principals I, III, Math - Certificate w/MCCC</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Cosmetology</td>\n      <td>Cosmetology</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Diesel Mechanics Technology/Technician</td>\n      <td>Diesel Mechanics Technology/Technician</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Electrical - Technical &amp; Apprentice-4 Years</td>\n      <td>Electrical - Technical &amp; Apprentice-4 Years</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Microsoft Excel</td>\n      <td>MS Excel</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Industrial Maintenance Mechanic</td>\n      <td>Industrial Maintenance Mechanic</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Machine Shop Practice</td>\n      <td>Machine Shop Practice</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Manicuring Licensing</td>\n      <td>Manicuring Licensing</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>TCP/IP and Cisco Networks</td>\n      <td>TCP/IP and Cisco Networks</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Mini Master of Business Adminstration</td>\n      <td>Mini MBA</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>TCP/IP and Cisco Networks Diploma</td>\n      <td>TCP/IP and Cisco Networks Diploma</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>LAN, Wide Area Network and Communication Diploma</td>\n      <td>LAN, WAN and Communication Diploma</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>Microsoft Certified Solutions Expert Windows 2...</td>\n      <td>MCSE Win 2K/Unix</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>Oracle and Unix</td>\n      <td>Oracle and Unix</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>Oracle and Unix</td>\n      <td>Oracle and Unix</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>Oracle Oracle Certification Program and C++/Java</td>\n      <td>Oracle OCP and C++/Java</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>A+/N+/Microsoft Certified Solutions Expert Win...</td>\n      <td>A+/N+/MCSE win 2K</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>Microsoft Certified Solutions Expert Windows 2000</td>\n      <td>MCSE Windows 2000</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>N+/Cisco Certified Networking Associate/Micros...</td>\n      <td>N+/CCNA/MCSE win 2K</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>Unix/Cisco Certified Networking Associate/Cisc...</td>\n      <td>Unix/CCNA/CCNP</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>Associate of Applied Science - Web Development</td>\n      <td>AAS - Web Development</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>Web Dev., XML and Java Script Diploma</td>\n      <td>Web Dev., XML and Java Script Diploma</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>Construction Trades Pre-Apprentice</td>\n      <td>Construction Trades Pre-Apprentice</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>Continuing Education Basic Selling Workshop</td>\n      <td>Contg. Ed. Basic Selling Workshop</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>Microsoft Power Point 2007 - Evening</td>\n      <td>Microsoft Power Point 2007 - Evening</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>Certified Nurse Aide - Evening</td>\n      <td>Certified Nurse Aide - Evening</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>A+ - Evening</td>\n      <td>A+ - Evening</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>Certified Phlebotomy Technician</td>\n      <td>Certified Phlebotomy Technician</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>Basic Plumbing - Evening</td>\n      <td>Basic Plumbing - Evening</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>Digital Camera - Evening</td>\n      <td>Digital Camera - Evening</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>High School Equivalency Exam Preparation (HSE)...</td>\n      <td>High School Equivalency Exam Preparation (HSE)...</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>Criminal Justice - Certificate</td>\n      <td>Criminal Justice - Certificate</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>Liberal Arts/Education - Associate in Arts Degree</td>\n      <td>Liberal Arts/Education - AA Degree</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>Liberal Arts/Women's Studies - Associate in Arts</td>\n      <td>Liberal Arts/Women's Studies - AA</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>Licensed Practical Nursing</td>\n      <td>Licensed Practical Nursing</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>TCP/IP and Cisco Networks Certificate</td>\n      <td>TCP/IP and Cisco Networks Certificate</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>Project S.H.A.R.E.</td>\n      <td>Project S.H.A.R.E.</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>Microsoft Certified System Administrator</td>\n      <td>Microsoft Certified System Administrator</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>Microsoft Certified System Engineer</td>\n      <td>Microsoft Certified System Engineer</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>Farm Stand Project</td>\n      <td>Farm Stand Project</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>Literacy Skills Development</td>\n      <td>Literacy Skills Development</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>Career Exploration &amp; Study Skills</td>\n      <td>Career Exploration &amp; Study Skills</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>Straight Truck Driver - Commerical Driver's Li...</td>\n      <td>Straight Truck Driver - CDL B</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>School Bus Driver - Commerical Driver's Licens...</td>\n      <td>School Bus Driver - CDL B w/ P\" &amp; \"S\"</td>\n    </tr>\n    <tr>\n      <th>50</th>\n      <td>Computerized Medical Office Specialist</td>\n      <td>Computerized Medical Office Specialist</td>\n    </tr>\n    <tr>\n      <th>51</th>\n      <td>Commerical Driver's License Class Class A</td>\n      <td>CDL A</td>\n    </tr>\n    <tr>\n      <th>52</th>\n      <td>Commerical Driver's License Class Class A w/ \"P\"</td>\n      <td>CDL A w/ \"P\"</td>\n    </tr>\n    <tr>\n      <th>53</th>\n      <td>A+/N+/Microsoft Office User Specialist</td>\n      <td>A+/N+/Mous</td>\n    </tr>\n    <tr>\n      <th>54</th>\n      <td>Microsoft Office User Specialist</td>\n      <td>MOUS</td>\n    </tr>\n    <tr>\n      <th>55</th>\n      <td>A+/N+/Unix</td>\n      <td>A+/N+/Unix</td>\n    </tr>\n    <tr>\n      <th>56</th>\n      <td>Microsoft Certified Solutions Expert Win2K/Cis...</td>\n      <td>MCSE Win2K/CCNA/CCNP</td>\n    </tr>\n    <tr>\n      <th>57</th>\n      <td>Automotive Engine Performance(AEP.CT)</td>\n      <td>Automotive Engine Performance(AEP.CT)</td>\n    </tr>\n    <tr>\n      <th>58</th>\n      <td>Black Seal Advanced/Stationary Engineer</td>\n      <td>Black Seal Advanced/Stationary Engineer</td>\n    </tr>\n    <tr>\n      <th>59</th>\n      <td>Medical Billing &amp; Coding Specialist</td>\n      <td>Medical Billing &amp; Coding Specialist</td>\n    </tr>\n    <tr>\n      <th>60</th>\n      <td>Medical Assistant</td>\n      <td>Medical Assistant</td>\n    </tr>\n    <tr>\n      <th>61</th>\n      <td>Microsoft Office Applications</td>\n      <td>Microsoft Office Applications</td>\n    </tr>\n    <tr>\n      <th>62</th>\n      <td>Computer Network &amp; Technical Support</td>\n      <td>Computer Network &amp; Technical Support</td>\n    </tr>\n    <tr>\n      <th>63</th>\n      <td>Microsoft Certified System Engineer</td>\n      <td>MS Certified System Engineer</td>\n    </tr>\n    <tr>\n      <th>64</th>\n      <td>Computerized Medical Office</td>\n      <td>Computerized Medical Office</td>\n    </tr>\n    <tr>\n      <th>65</th>\n      <td>Personal Computer Assembly &amp; Troubleshooting</td>\n      <td>PC Assembly &amp; Troubleshooting</td>\n    </tr>\n    <tr>\n      <th>66</th>\n      <td>Office Assistant Specialist Series</td>\n      <td>Office Assistant Specialist Series</td>\n    </tr>\n    <tr>\n      <th>67</th>\n      <td>Image Graphic Design</td>\n      <td>Image Graphic Design</td>\n    </tr>\n    <tr>\n      <th>68</th>\n      <td>Oracle Developer/2000 &amp; Web Application</td>\n      <td>Oracle Developer/2000 &amp; Web Application</td>\n    </tr>\n    <tr>\n      <th>69</th>\n      <td>Network Specialist</td>\n      <td>Network Specialist</td>\n    </tr>\n    <tr>\n      <th>70</th>\n      <td>Adobe Photoshop CS Advanced</td>\n      <td>Adobe Photoshop CS Advanced</td>\n    </tr>\n    <tr>\n      <th>71</th>\n      <td>Finance Certificate</td>\n      <td>Finance Certificate</td>\n    </tr>\n    <tr>\n      <th>72</th>\n      <td>Accountancy Certificate</td>\n      <td>Accountancy Certificate</td>\n    </tr>\n    <tr>\n      <th>73</th>\n      <td>Business Management Certificate</td>\n      <td>Business Management Certificate</td>\n    </tr>\n    <tr>\n      <th>74</th>\n      <td>International Business and Trade</td>\n      <td>International Business and Trade</td>\n    </tr>\n    <tr>\n      <th>75</th>\n      <td>Management Information Systems</td>\n      <td>Management Information Systems</td>\n    </tr>\n    <tr>\n      <th>76</th>\n      <td>High School Equivalence</td>\n      <td>High School Equivalence</td>\n    </tr>\n    <tr>\n      <th>77</th>\n      <td>Microsoft Project</td>\n      <td>Microsoft Project</td>\n    </tr>\n    <tr>\n      <th>78</th>\n      <td>Microsoft Visio</td>\n      <td>Microsoft Visio</td>\n    </tr>\n    <tr>\n      <th>79</th>\n      <td>Adult Basic Education Program</td>\n      <td>Adult Basic Education Program</td>\n    </tr>\n    <tr>\n      <th>80</th>\n      <td>Office Support Assistant (Day/Eve)</td>\n      <td>Office Support Assistant (Day/Eve)</td>\n    </tr>\n    <tr>\n      <th>81</th>\n      <td>Computer-aided design I &amp; II - 2 years</td>\n      <td>CAD I &amp; II - 2 years</td>\n    </tr>\n    <tr>\n      <th>82</th>\n      <td>Automotive Technology - Certificate</td>\n      <td>Automotive Technology - Certificate</td>\n    </tr>\n    <tr>\n      <th>83</th>\n      <td>Automotive Mechanics - General</td>\n      <td>Automotive Mechanics - General</td>\n    </tr>\n    <tr>\n      <th>84</th>\n      <td>Basics - Blue Print Reading I - Machine/Buildi...</td>\n      <td>Basics - Blue Print Reading I - Machine/Buildi...</td>\n    </tr>\n    <tr>\n      <th>85</th>\n      <td>Administrative Assistant</td>\n      <td>Administrative Assistant</td>\n    </tr>\n    <tr>\n      <th>86</th>\n      <td>Statistical Analysis (SAS, Clinical SAS)</td>\n      <td>Statistical Analysis (SAS, Clinical SAS)</td>\n    </tr>\n    <tr>\n      <th>87</th>\n      <td>Oracle Database Administration</td>\n      <td>Oracle Database Administration</td>\n    </tr>\n    <tr>\n      <th>88</th>\n      <td>Paralegal Studies</td>\n      <td>Paralegal Studies</td>\n    </tr>\n    <tr>\n      <th>89</th>\n      <td>Fashion Merchandising</td>\n      <td>Fashion Merchandising</td>\n    </tr>\n    <tr>\n      <th>90</th>\n      <td>General Education Diploma &amp; Computer Literacy</td>\n      <td>GED &amp; Computer Literacy</td>\n    </tr>\n    <tr>\n      <th>91</th>\n      <td>Legal  Assistant</td>\n      <td>Legal  Assistant</td>\n    </tr>\n    <tr>\n      <th>92</th>\n      <td>Medical Assisting</td>\n      <td>Medical Assisting</td>\n    </tr>\n    <tr>\n      <th>93</th>\n      <td>Business Administration with Computerized Acco...</td>\n      <td>Business Administration with Computerized Acco...</td>\n    </tr>\n    <tr>\n      <th>94</th>\n      <td>Shielded Metal Arc Welding Shielded Metal Arc ...</td>\n      <td>SMAW Shielded Metal Arc Welding-4G</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>Gas Tungsten Arc Welding 3/4G/American Welding...</td>\n      <td>Gas Tungsten Arc Welding 3/4G/AWS Prep Course</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>Executive Assistant</td>\n      <td>Executive Assistant</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>Welding Technology/ Welder</td>\n      <td>Welding Technology/ Welder</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>Microsoft Word</td>\n      <td>MS Word</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>Oracle Certified Professional Database Adminis...</td>\n      <td>Oracle Certified Professional DBA</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 81
    }
   ],
   "source": [
    "# Now we do a mass search and replace on STANDARDIZED_NAME_1 and STANDRADIZED_NAME with the labels that we have\n",
    "\n",
    "# We follow this overflow thread\n",
    "# see: https://stackoverflow.com/a/48887382/3662899\n",
    "\n",
    "# First, construct an abbreviation to its expansion  dictionary\n",
    "label_mapper =\\\n",
    "    pd.DataFrame(\n",
    "        {\n",
    "            \"abbreviation\": \\\n",
    "abbreviations_to_label.abbreviation[:last_labeled_index].values,\n",
    "            \"expanded\": expanded_labels[:last_labeled_index]\n",
    "        }\n",
    "    )\n",
    "copy_over_index = (label_mapper.expanded == \"No Label\") | (label_mapper.expanded == \"Submit.\")\n",
    "label_mapper.expanded[copy_over_index] =\\\n",
    "    label_mapper.abbreviation[copy_over_index]\n",
    "\n",
    "# Add in one-off acronyms observed through labelling that need attention\n",
    "# too do, make this json or a python file\n",
    "one_off_mappings =(\n",
    "    ['AAS', 'Associate of Applied Science'],\n",
    "    ['ESL', 'English as a Second Language'],\n",
    "    ['Bus.Soft.', 'Business Software'],\n",
    "    ['App', 'Application'],\n",
    "    ['App.', 'Application'],\n",
    "    ['Dev.', 'Developer'],\n",
    "    ['CDL', 'Commerical Driver\\'s License'],\n",
    "    ['win', 'Windows'],\n",
    "    ['Win', 'Windows'],    \n",
    "    ['Contg.', 'Continuing'],\n",
    "    ['Ed.', 'Education'],\n",
    "    ['Mgmt.', 'Management'],\n",
    "    ['Mous', 'Microsoft Office User Specialist']\n",
    ")\n",
    "\n",
    "for mapping in one_off_mappings:\n",
    "    label_mapper.loc[len(label_mapper)+1] = mapping\n",
    "\n",
    "# normally we'd map through rep_dict but we want matches to occur\n",
    "# on word-like boundaries, space, /, and :, we use re.escape to properly escape\n",
    "\n",
    "# # Todo: the space regex forces matches at start of string to drop\n",
    "# #  need to make a regex that includes ^ starts\n",
    "# space = \" \"\n",
    "# slash = \"/\"\n",
    "# colon = \":\"\n",
    "# rep_dict = {\n",
    "#     **dict(zip(label_mapper.abbreviation+space, label_mapper.expanded+space)),\n",
    "#     **dict(zip(label_mapper.abbreviation+slash, label_mapper.expanded+slash)),\n",
    "#     **dict(zip(label_mapper.abbreviation+colon, label_mapper.expanded+colon))\n",
    "# }\n",
    "\n",
    "rep_dict = {\n",
    "    **dict(zip(label_mapper.abbreviation, label_mapper.expanded))\n",
    "}\n",
    "\n",
    "\n",
    "#pattern = re.compile(\"[\\b\\W]|\".join([re.escape(k) for k in rep_dict.keys()]), re.M)\n",
    "pattern = re.compile(\n",
    "    \"|\".join([re.escape(k) for k in rep_dict.keys()]),\n",
    "    re.M)\n",
    "\n",
    "def my_lookup(x):\n",
    "    if not rep_dict.get(x, False):\n",
    "        return rep_dict.get(x[1:], False)\n",
    "\n",
    "start_abbrev = re.compile(\n",
    "    \"^\"+\"|^\".join([re.escape(k) for k in rep_dict.keys()]), re.M)\n",
    "start_abbrev = re.compile(\n",
    "    \"^HVAC\", re.M)\n",
    "\n",
    "def multiple_replace(string):\n",
    "    return pattern.sub(lambda x: rep_dict[x.group(0)], string)\n",
    "\n",
    "def multiple_replace2(string):\n",
    "    return start_abbrev.sub(\n",
    "        lambda x: my_lookup(x), string)\n",
    "\n",
    "def term_grouped_regex(term=\"\", right_regex=\"\", left_regex=\"\"):\n",
    "    #return left_regex + '(' + re.escape(term) + ')' + right_regex\n",
    "    mystr = left_regex + '(' +\\\n",
    "                f\"?P<{term}>\"   +\\\n",
    "                re.escape(term) +\\\n",
    "            ')' +\\\n",
    "            right_regex\n",
    "    return mystr\n",
    "\n",
    "def make_term_grouped_regex(term=\"\", right_regex=\"\", left_regex=\"\"):\n",
    "    mystr = left_regex + '(' +\\\n",
    "                re.escape(term) +\\\n",
    "            ')' + right_regex\n",
    "    return mystr\n",
    "\n",
    "\n",
    "def make_grouped_regexes(replace_dict, left_regex=\"\", right_regex=\"\"):\n",
    "    return (make_term_grouped_regex(left_regex=left_regex,\n",
    "                                    term=key,\n",
    "                                    right_regex=right_regex)\\\n",
    "                                        for key in replace_dict.keys()\n",
    "            )\n",
    "\n",
    "# a_abbrev = re.compile(\n",
    "#     \"|\".join([\n",
    "#         make_term_grouped_regex(\n",
    "#             left_regex=\"^\",\n",
    "#             term=k\n",
    "#         ) for k in rep_dict.keys()]), re.M)\n",
    "    # \"|\".join(\n",
    "    #     make_grouped_regexes(rep_dict, left_regex=\"^\")\n",
    "    # ) +\\\n",
    "\n",
    "\n",
    "a_abbrev = re.compile(\n",
    "    \"|\".join(\n",
    "        make_grouped_regexes(rep_dict, left_regex=r'\\s', right_regex=r'\\s')\n",
    "    )\n",
    ")\n",
    "\n",
    "draft_output = the_df.iloc[:100,:][['NAME_1']]\n",
    "pd.set_option('display.max_rows', None)\n",
    "# draft_output['MULTI_REPLACE_STANDARDIZEDNAME_1'] =\\\n",
    "#     draft_output['NAME_1'].map(multiple_replace3)\n",
    "# draft_output[['MULTI_REPLACE_STANDARDIZEDNAME_1', 'NAME_1']]\n",
    "\n",
    "the_content = re.compile(r'\\b(?P<key>\\w+)\\b')\n",
    "\n",
    "test_string = 'Straight Truck Driver - CDL B'\n",
    "test_string = \"Bus.Soft. App/Office Proc.Legal/\"\n",
    "\n",
    "def lookup_match(matchobj):\n",
    "    #  The match corresponds to a key with regexs \n",
    "    # surrounding it. To properly replace it we\n",
    "    # replace the key with its value in the whole matched\n",
    "    # string\n",
    "    the_original_string = matchobj.group(0)\n",
    "    print('in lookup match')\n",
    "\n",
    "    the_key = the_content.search(\n",
    "        matchobj.group(0)\n",
    "        ).group('key')\n",
    "\n",
    "    the_value = rep_dict.get(the_key, None)\n",
    "    if not the_value:\n",
    "        # try the whole thing\n",
    "        #print(rep_dict)\n",
    "        #print(the_original_string.strip())\n",
    "        the_value = rep_dict[the_original_string.strip()]\n",
    "        # we then use the entire string\n",
    "        print(the_key, \"|\", the_original_string)\n",
    "\n",
    "    print(the_key, \"|\", the_original_string)\n",
    "    #return the_original_string.replace(lookup_match, the_value)\n",
    "    return the_original_string.replace(the_key, the_value)\n",
    "\n",
    "\n",
    "def lookup_match(matchobj):\n",
    "    #  The match corresponds to a key with regexs \n",
    "    # surrounding it. To properly replace it we\n",
    "    # replace the key with its value inside of the whole matched\n",
    "    # string.\n",
    "\n",
    "    # This is overly complicated but we have a problem\n",
    "    # of ambiguity in that the keys \"Bus\" and \"Bus.Proc.\"\n",
    "    # will both match to \"Bus\" if you strip out possible\n",
    "    # left and right regexes; there is no way to know that\n",
    "    # the periods in \"Bus.Proc.\" don't indicate any character,\n",
    "    # e.g. \"BusXProcY\"\n",
    "    #\n",
    "    # So what we do is use the beg-for-forgiveness paradigm\n",
    "    # and first attempt to match to the large possible match (\"Bus.Proc.\")\n",
    "    # and then match to the content found by a specialized regex only\n",
    "    # if that fails\n",
    "    the_original_string = matchobj.group(0)\n",
    "\n",
    "    the_key = the_original_string.strip()\n",
    "    final_word = rep_dict.get(\n",
    "        the_key,\n",
    "        None\n",
    "    )\n",
    "\n",
    "    if not final_word:\n",
    "        shorter_key = the_content.search(\n",
    "            the_original_string\n",
    "            ).group('key')\n",
    "        final_word = rep_dict[shorter_key]\n",
    "        the_key = shorter_key\n",
    "\n",
    "    return the_original_string.replace(the_key, final_word)\n",
    "\n",
    "\n",
    "# See: https://stackoverflow.com/a/61952495/3662899\n",
    "# So, we can have more than one match in a given string, so we \n",
    "# need to \n",
    "\n",
    "# Here we have a bank of regexs for very specific left, rgith situations\n",
    "#   we could combine them for efficiency but it's easier to debug, examine\n",
    "#   in a special case row by row bank\n",
    "a_abbrev = re.compile(\n",
    "    \"|\".join(\n",
    "        make_grouped_regexes(rep_dict, left_regex=r'^', right_regex=r'\\s')\n",
    "    ) + \"|\" +\\\n",
    "    \"|\".join(\n",
    "        make_grouped_regexes(rep_dict, left_regex=r'\\s', right_regex=r'\\s')\n",
    "    ) + \"|\" +\\\n",
    "    \"|\".join(\n",
    "        make_grouped_regexes(rep_dict, left_regex=r'^', right_regex=r'$')\n",
    "    ) + \"|\" +\\\n",
    "    \"|\".join(\n",
    "        make_grouped_regexes(rep_dict, left_regex=r'[\\s/]', right_regex=r'$')\n",
    "    ) + \"|\" +\\\n",
    "    \"|\".join(\n",
    "        make_grouped_regexes(rep_dict, left_regex=r'/', right_regex=r'[\\s/]')\n",
    "    )    \n",
    ")\n",
    "\n",
    "def multiple_replace(string):\n",
    "    return a_abbrev.sub(lookup_match, string)\n",
    "\n",
    "#re.sub(r'\\s'+'(?P<CDL>CDL)'+r'\\s' + '|' + \"(?P<woot>ABC)\", dashrepl, test_string)\n",
    "\n",
    "#print(a_abbrev)\n",
    "# test_string = \"A+/N+/Mous\"\n",
    "# test_string = \"/MOUS\"\n",
    "# test_string = \"Mous\"\n",
    "\n",
    "# k = re.compile(\"MOUS|^Mous$\")\n",
    "# print( test_string in label_mapper.abbreviation)\n",
    "# print( test_string in rep_dict, rep_dict[test_string])\n",
    "# print(\"|\"+label_mapper.abbreviation.iloc[-1]+'|')\n",
    "\n",
    "# print(\n",
    "#     k.sub(\"Microsoft Office User Something\", test_string)\n",
    "# )\n",
    "\n",
    "#print(a_abbrev.pattern[100:])\n",
    "\n",
    "# print(a_abbrev)\n",
    "# k =multiple_replace(test_string)\n",
    "# print(test_string)\n",
    "# print(k)\n",
    "\n",
    "draft_output['MULTI_REPLACE_STANDARDIZEDNAME_1'] =\\\n",
    "    draft_output['NAME_1'].map(multiple_replace)\n",
    "\n",
    "# so, see: https://stackoverflow.com/a/61952495/3662899\n",
    "# or we just run two times, again. Pretty simple, not scalable in the limit but whatever? in some sense it's probably about the same givne that we loop a constant\n",
    "# number of times and I treat the scan and replace as O(1)\n",
    "draft_output['MULTI_REPLACE_STANDARDIZEDNAME_1'] =\\\n",
    "    draft_output['MULTI_REPLACE_STANDARDIZEDNAME_1'].map(multiple_replace)\n",
    "draft_output['MULTI_REPLACE_STANDARDIZEDNAME_1'] =\\\n",
    "    draft_output['MULTI_REPLACE_STANDARDIZEDNAME_1'].map(multiple_replace)\n",
    "\n",
    "\n",
    "draft_output[['MULTI_REPLACE_STANDARDIZEDNAME_1', 'NAME_1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "done\n"
    }
   ],
   "source": [
    "# Here we ingest Career One Stop certifications\n",
    "#   I was goign to use this to de-acroymn-ize mentions but now am unsure\n",
    "# if this is critical. It also may introduce errors, e.g. AES mapping to\n",
    "# the \"wrong acroymn\"\n",
    "\n",
    "# Here we read in a .sql directly as text and parse out the data.\n",
    "# I do this to avoid the need for a database, db drivers, etc. \n",
    "# That said, this represented some investment in constructing the right regexs\n",
    "if not SKIP_THIS:\n",
    "    path = rootpath + externalpath + 'career_one_stop/'\n",
    "    credential_sql = 'TEST-2-CERTIFICATIONS.sql' # '2-CERTIFICATIONS.sql'\n",
    "\n",
    "    with open(path + credential_sql) as sql:\n",
    "        my_string = sql.read()\n",
    "\n",
    "    header_names =\\\n",
    "        (\n",
    "            'CERT_ID', 'CERT_NAME', 'ORG_ID', 'TRAINING', 'EXPERIENCE', \n",
    "            'EITHER', 'EXAM', 'RENEWAL', 'CEU', 'REEXAM', \n",
    "            'CPD', 'CERT_ANY', 'URL', 'ACRONYM', 'NSSB_URL', \n",
    "            'CERT_URL', 'CERT_LAST_UPDATE', 'KEYWORD1', 'KEYWORD2', 'KEYWORD3', \n",
    "            'SUPPRESS', 'DATEADDED', 'COMMENTS', 'VERIFIED', 'UPDATEDBY', \n",
    "            'CERT_DESCRIPTION', 'DELETED', 'EXAM_DETAILS'\n",
    "        )\n",
    "\n",
    "    # Pandas assumes atomic python types when reading from records,\n",
    "    # See: https://github.com/pandas-dev/pandas/issues/9381, so we need to use\n",
    "    # Python types here\n",
    "    dtypes =\\\n",
    "        np.dtype(\n",
    "            \"str, str, float, float,\"\n",
    "            \"float, float, float, str,\"\n",
    "            \"float, float, float, float,\"\n",
    "            \"str, str, str, str,\"\n",
    "            \"str, str, str, str,\"\n",
    "            \"str, str, str, str,\" \n",
    "            \"str, str, float, str\"\n",
    "        )\n",
    "\n",
    "    flags = re.MULTILINE | re.DOTALL | re.VERBOSE\n",
    "    the_fields_regex =\\\n",
    "        \"\"\"\n",
    "        (?P<values>Values\\n\\s+\\()  # Start with the word Value <newline> (\n",
    "            (?P<fields>.*?)        #    Grab all the field content\n",
    "        (?P<end>\\);)               # ... which stops at the terminating paren, ;\n",
    "        \"\"\"\n",
    "\n",
    "    the_fields = re.compile(the_fields_regex, flags=flags)\n",
    "\n",
    "    a_field_regex =\\\n",
    "        \"\"\"\n",
    "        '(?P<string>.*?)'[,)]           # get a quoted string ending at comma or paran or\n",
    "        |(?P<date_time>TO_DATE\\(.*?\\))  # get the TO_DATE, parse out actual date later or\n",
    "        |(?P<num>\\d),                   # get numeric or\n",
    "        |(?P<null>NULL)                 # get NULL\n",
    "        \"\"\"\n",
    "\n",
    "    a_field = re.compile(a_field_regex, flags=flags)\n",
    "\n",
    "    require_field_numbers = [1] # should be 13\n",
    "\n",
    "    def yield_certification_records(sql_file=my_string, require_field_numbers=require_field_numbers):\n",
    "        # do we skip those w/o certain fields, like acronymns\n",
    "        temp_data = [0]*28\n",
    "        for match in the_fields.finditer(sql_file):\n",
    "            break_match = False\n",
    "\n",
    "            for index, field in enumerate(a_field.finditer( match.group('fields') )):\n",
    "                grp = None\n",
    "                for grp, value in field.groupdict().items():\n",
    "                    if value:\n",
    "                        # then we transform the string value into the appropriate type, given the group name\n",
    "                        if grp == 'date_time':\n",
    "                            #  There is a difference between https://regex101.com/r/yphUXY/1/\n",
    "                            # and what I see Python do here; if I don't capture the entire thing\n",
    "                            # it gets re-raised as another potential match, even if I use ?:, etc.\n",
    "                            value = value[9:28] # todo: convert to datetime\n",
    "                        if grp == 'null':\n",
    "                            value = None\n",
    "                            if index in require_field_numbers:\n",
    "                                break_match = True\n",
    "\n",
    "                        if grp == 'num':\n",
    "                            value = int(value)\n",
    "\n",
    "                        temp_data[index] = value\n",
    "                        break # only one possible match value\n",
    "                if break_match: # and don't look at other fields\n",
    "                    break\n",
    "\n",
    "            if not break_match:\n",
    "                yield tuple(value for value in temp_data)\n",
    "            \n",
    "            break_match = False\n",
    "\n",
    "    certification_df =\\\n",
    "        pd.DataFrame.from_records(\n",
    "            yield_certification_records(),\n",
    "            columns=header_names)\n",
    "    certification_df\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) \n",
    "# Then go after odd static patterns that are common \n",
    "# ... A.A., AAS,e ends-with \"/\", etc etc\n",
    "# \"Applied Certificate in...\" <--- thing is, this could really be a program\n",
    "# the_df.STANDARDIZEDNAME_1 =\\\n",
    "#     the_df.STANDARDIZEDNAME_1.str.replace(\"A.A.\",\"\", case=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This is the evaluation part of the program and course name standardizations\n",
    "# along with the provider name. My goal is to have 85%+ standardized, send out\n",
    "# that 85% will come from the jefferey's interval\n",
    "\n",
    "# Evaluation Rubric:\n",
    "#   A) Here we label clearly wrong snippets, anything that is marginal we mark as\n",
    "# standardized for purposes of this evaluation because we want to err on the side\n",
    "# of giving overly specific information, which includes odd info\n",
    "#   B) We also click through quickly, not overly dwelling one any one example, the\n",
    "# goal here is to get the evaulation done quickly since it's so manual\n",
    "#   C) For now we ignore casingl there does need to be a camel casing applied to\n",
    "# all caps\n",
    "\n",
    "# We create a series of data to evaluate\n",
    "columns_to_check = ['MULTI_REPLACE_STANDARDIZEDNAME_1', 'STANDARDIZEDNAME']\n",
    "the_data =\\\n",
    "    np.concatenate(\n",
    "        (\n",
    "            draft_output[columns_to_check[0]].to_numpy(),\n",
    "            the_df[columns_to_check[1]].to_numpy()\n",
    "        )\n",
    "    )\n",
    "    \n",
    "# we shuffle the data to elminate any bias across/within the columns when\n",
    "# evaluting\n",
    "random.Random(42).shuffle(the_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "ClassLabeller(children=(HBox(children=(HBox(children=(FloatProgress(value=0.0, description='Progress:', max=1.",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a37b5fe2f96a4f35a9c91cca25d2d6ca"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "def display_func(row):\n",
    "    \"\"\"\n",
    "    The display function gets passed your data - in the\n",
    "    case of a dataframe, it gets passed a row - and then\n",
    "    has to \"display\" your data in whatever way you want.\n",
    "\n",
    "    It doesn't need to return anything\n",
    "    \"\"\"\n",
    "    display(Markdown(row))\n",
    "    #display(Markdown(\"**At:** \" + row[\"timestamp\"]))\n",
    "\n",
    "def preprocessor(x, y):\n",
    "    # only take standardized column, leave everything else\n",
    "    return x, y\n",
    "\n",
    "verification_widget = ClassLabeller(\n",
    "    features=the_data,\n",
    "    model=pipeline,\n",
    "    model_preprocess=preprocessor,\n",
    "    display_func=display_func,\n",
    "    options=['standardized', 'not standardized'],\n",
    "    acquisition_function='margin'\n",
    ")\n",
    "\n",
    "verification_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "jeffreys bionomial proportion is: [0.99, 0.99]\nWe examined 102 labels, of which 101 are correct.\n"
    }
   ],
   "source": [
    "# insert bionomial proprtion esimator here\n",
    "\n",
    "def print_CI(labels, response_is_standardized = \"standardized\", method = \"jeffreys\"):\n",
    "    successful_count = sum(\n",
    "        response_is_standardized == label for label in labels\n",
    "    )\n",
    "    not_examined_count = sum(\n",
    "        None == label for label in labels\n",
    "    )\n",
    "\n",
    "    CI = proportion_confint(\n",
    "            count= successful_count,\n",
    "            nobs= len(labels) - not_examined_count,\n",
    "            alpha = 0.95,\n",
    "            method=method\n",
    "        )\n",
    "    print(f\"{method} bionomial proportion is: [{CI[0]:.2f}, {CI[1]:.2f}]\",\n",
    ")\n",
    "    print(f\"We examined {len(labels) - not_examined_count} labels, of which {successful_count} are correct.\")\n",
    "print_CI(labels=verification_widget.new_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "done\n"
    }
   ],
   "source": [
    "# 4)\n",
    "# Now we write out the verfiied results\n",
    "# ... finally we can write this out as our first complete lookup table\n",
    "# for the NAME field\n",
    "write_out = the_df\n",
    "\n",
    "write_out['STANDARDIZEDNAME_1'] =\\\n",
    "    draft_output['MULTI_REPLACE_STANDARDIZEDNAME_1']\n",
    "\n",
    "# shuffe the rows to better remove temporal baises\n",
    "write_out =\\\n",
    "    the_df.sample(frac=1, random_state=42, axis=0).reset_index(drop=True)\n",
    "\n",
    "write_out.to_csv(rootpath + interimpath + content_is + \".csv\",\n",
    "                index = False,\n",
    "                chunksize = 10000,\n",
    "                columns=columns_to_save)\n",
    "\n",
    "write_out.to_excel(rootpath + processedpath + content_is + \".xls\",\n",
    "            sheet_name=\"Standardized NAME and NAME_1\",\n",
    "            index=False,\n",
    "            columns=columns_to_save)\n",
    "print('done')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37264bitd4adstandardizationpipenvcac7d9f4a0864f29b6353caf0213501a",
   "display_name": "Python 3.7.2 64-bit ('d4ad_standardization': pipenv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}